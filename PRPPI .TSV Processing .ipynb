{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b57beefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy!=1.24.0,>=1.17 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from seaborn) (1.24.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/vlad/Desktop/Test_Osprey_Che/February2023/env_prppi/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "444ac01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6y4o', '2bcx', '6xxf']\n",
      "['A11=glu', 'A14=glu', 'A15=ala', 'A18=leu', 'A19=phe', 'A27=ile', 'A32=leu', 'A35=val', 'A36=met', 'A38=ser', 'A39=leu', 'A41=gln', 'A47=glu', 'A51=met', 'A52=ile', 'A54=glu', 'A55=val', 'A63=ile', 'A68=phe', 'A71=met', 'A72=met', 'A74=arg', 'A75=lys']\n"
     ]
    }
   ],
   "source": [
    "# this code creates two lists to use them for building tables from TSV\n",
    "\n",
    "import os\n",
    "\n",
    "def read_sequence_column(tsv_file):\n",
    "    with open(tsv_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find the index of the \"Sequence\" column in the header row\n",
    "    header_row = lines[1].strip().split('\\t')\n",
    "    sequence_index = header_row.index('Sequence')\n",
    "\n",
    "    # Extract values from the first row (\"data1\") and store them in a set to avoid duplicates\n",
    "    unique_values = set()\n",
    "    data_row = lines[0].strip().split('\\t')  # Read only the first data row\n",
    "    unique_values.add(data_row[sequence_index])\n",
    "\n",
    "    return unique_values\n",
    "\n",
    "def extract_unique_name_fragments(tsv_file, unique_name_fragments_set):\n",
    "    basename = os.path.basename(tsv_file)\n",
    "    start_index = basename.find(\"bbkstar_results_\") + len(\"bbkstar_results_\")\n",
    "    end_index = basename.find(\"_A\")\n",
    "    unique_name_fragment = basename[start_index:end_index]\n",
    "\n",
    "    # Check if the unique_name_fragment is already in the set\n",
    "    if unique_name_fragment not in unique_name_fragments_set:\n",
    "        unique_name_fragments_set.add(unique_name_fragment)\n",
    "        return unique_name_fragment\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_tsv_files_paths(base_dir):\n",
    "    tsv_files = []\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.tsv'):\n",
    "                tsv_files.append(os.path.join(root, file))\n",
    "    return tsv_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = \"/home/vlad/Desktop/Sucessful_Osprey_February/result\"  # Replace this with the actual path to the parent directory\n",
    "    tsv_files_paths = get_tsv_files_paths(base_directory)\n",
    "\n",
    "    # Create a set to store unique name fragments\n",
    "    unique_name_fragments = set()\n",
    "    \n",
    "    unique_sequences = set()\n",
    "    for tsv_file in tsv_files_paths:\n",
    "        sequences = read_sequence_column(tsv_file)\n",
    "        unique_sequences.update(sequences)\n",
    "        \n",
    "        unique_name_fragment = extract_unique_name_fragments(tsv_file, unique_name_fragments)\n",
    "        if unique_name_fragment is not None:\n",
    "            list_of_unique_name_fragments = list(unique_name_fragments)\n",
    "\n",
    "    # Sort the unique sequences by numerical values (ignoring letters)\n",
    "    sorted_unique_sequences = sorted(unique_sequences, key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "\n",
    "\n",
    "#     # Print the resulting list\n",
    "print(list_of_unique_name_fragments)\n",
    "print(sorted_unique_sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70c89b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    6y4o      2bcx      6xxf\n",
      "WT_amino_acids                              \n",
      "A11=glu              NaN  0.000000  0.485841\n",
      "A14=glu              NaN  0.231432  0.267061\n",
      "A15=ala              NaN  0.000000  1.990904\n",
      "A18=leu              NaN  0.000000  0.144689\n",
      "A19=phe         0.000000  0.000000  0.000000\n",
      "A27=ile         0.206819  0.008724  0.000000\n",
      "A32=leu         0.000000  0.015981  0.000000\n",
      "A35=val         0.325599  0.000000  2.673205\n",
      "A36=met         0.000000  0.000000  0.000000\n",
      "A38=ser         3.897585  3.471798  4.589735\n",
      "A39=leu         3.141124  0.000000  0.000000\n",
      "A41=gln         2.593957  3.167038  0.289900\n",
      "A47=glu              NaN  0.000000       NaN\n",
      "A51=met         0.000000  0.000000  0.627191\n",
      "A52=ile         0.063553  0.161253  0.000000\n",
      "A54=glu              NaN  0.926277  4.178508\n",
      "A55=val         0.000000  0.000000  0.000000\n",
      "A63=ile         0.289148  0.113335  0.000000\n",
      "A68=phe         0.000000  0.000000  0.000000\n",
      "A71=met         0.000000  0.000000  0.000000\n",
      "A72=met         0.000000  0.000000  0.000000\n",
      "A74=arg              NaN  0.518911       NaN\n",
      "A75=lys         2.000744  0.565107  0.000000\n",
      "               6y4o 2bcx 6xxf\n",
      "WT_amino_acids               \n",
      "A11=glu         NaN  glu  ASP\n",
      "A14=glu         NaN  ASP  ASP\n",
      "A15=ala         NaN  ala  GLU\n",
      "A18=leu         NaN  leu  GLN\n",
      "A19=phe         phe  phe  phe\n",
      "A27=ile         LEU  GLN  ile\n",
      "A32=leu         leu  MET  leu\n",
      "A35=val         ILE  val  GLU\n",
      "A36=met         met  met  met\n",
      "A38=ser         ASP  ASP  ASP\n",
      "A39=leu         GLU  leu  leu\n",
      "A41=gln         GLU  GLU  MET\n",
      "A47=glu         NaN  glu  NaN\n",
      "A51=met         met  met  ARG\n",
      "A52=ile         MET  MET  ile\n",
      "A54=glu         NaN  TRP  LYS\n",
      "A55=val         val  val  val\n",
      "A63=ile         VAL  ASN  ile\n",
      "A68=phe         phe  phe  phe\n",
      "A71=met         met  met  met\n",
      "A72=met         met  met  met\n",
      "A74=arg         NaN  TYR  NaN\n",
      "A75=lys         TYR  ARG  lys\n"
     ]
    }
   ],
   "source": [
    "# this code creates two tables you can use to build a heatmap from TSV data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_sequence_column(tsv_file):\n",
    "    with open(tsv_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find the index of the \"Sequence\" column in the header row\n",
    "    header_row = lines[1].strip().split('\\t')\n",
    "    sequence_index = header_row.index('Sequence')\n",
    "\n",
    "    # Extract values from the row with \"Seq ID\" as the sequence\n",
    "    row0_data = lines[0].strip().split('\\t')\n",
    "    row2_data = lines[2].strip().split('\\t')\n",
    "\n",
    "    # Find the index of the \"K* Score (Log10)\" column in the header row\n",
    "    k_score_index = header_row.index('K* Score (Log10)')\n",
    "\n",
    "    # Subtract values of row2 from row0 for the \"K* Score (Log10)\" column\n",
    "    k_delta = float(row2_data[k_score_index]) - float(row0_data[k_score_index])\n",
    "\n",
    "    # Get the value of the \"Sequence\" column from row2\n",
    "    sequence_wt = row0_data[sequence_index]\n",
    "    sequence_mut = row2_data[sequence_index].split('=')[1]\n",
    "\n",
    "#     print(sequence, k_delta)\n",
    "    return sequence_wt, sequence_mut, k_delta\n",
    "\n",
    "def get_tsv_files_paths(base_dir):\n",
    "    tsv_files = []\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.tsv'):\n",
    "                tsv_files.append(os.path.join(root, file))\n",
    "    return tsv_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = \"/home/vlad/Desktop/Sucessful_Osprey_February/result\"\n",
    "    tsv_files_paths = get_tsv_files_paths(base_directory)\n",
    "\n",
    "    # ... (existing code to get unique sequences and name fragments) ...\n",
    "\n",
    "    # Create an empty dictionary to store the data for the DataFrame\n",
    "    data_dict1 = {'WT_amino_acids': []}\n",
    "    data_dict2 = {'WT_amino_acids': []}\n",
    "\n",
    "    for name_fragment in list_of_unique_name_fragments:\n",
    "        data_dict1[name_fragment] = []\n",
    "        data_dict2[name_fragment] = []\n",
    "\n",
    "    # Process each TSV file\n",
    "    for tsv_file in tsv_files_paths:\n",
    "        # Check if the file name contains any value from list_of_unique_name_fragments\n",
    "        if any(name_fragment in os.path.basename(tsv_file) for name_fragment in list_of_unique_name_fragments):\n",
    "            sequence_wt, sequenc_mut, k_delta = read_sequence_column(tsv_file)\n",
    "\n",
    "            # Append data to the dictionary\n",
    "            data_dict1['WT_amino_acids'].append(sequence_wt)\n",
    "            data_dict2['WT_amino_acids'].append(sequence_wt)\n",
    "\n",
    "            # Find the matching name fragment and store the k_delta value\n",
    "            for name_fragment in list_of_unique_name_fragments:\n",
    "                if name_fragment in os.path.basename(tsv_file):\n",
    "                    data_dict1[name_fragment].append(k_delta)\n",
    "                    data_dict2[name_fragment].append(sequenc_mut)\n",
    "                else:\n",
    "                    data_dict1[name_fragment].append(float('nan'))\n",
    "                    data_dict2[name_fragment].append(float('nan'))\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df1 = pd.DataFrame(data_dict1)\n",
    "    df1.set_index('WT_amino_acids', inplace=True)\n",
    "    df2 = pd.DataFrame(data_dict2)\n",
    "    df2.set_index('WT_amino_acids', inplace=True)\n",
    "    \n",
    "    df1.sort_values(by='WT_amino_acids', ascending=True, inplace=True)    \n",
    "    df2.sort_values(by='WT_amino_acids', ascending=True, inplace=True)\n",
    "    merged_df1 = df1.groupby('WT_amino_acids').max()\n",
    "    \n",
    "def custom_merge(series):\n",
    "    return series.apply(lambda x: ', '.join(x.dropna().unique()) if x.notnull().any() else \"NaN\")\n",
    "\n",
    "# Apply the custom_merge function to each group of rows with the same index ('WT_amino_acids')\n",
    "merged_df2 = df2.groupby('WT_amino_acids').apply(custom_merge)\n",
    "\n",
    "print(merged_df1)\n",
    "print(merged_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0843ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
